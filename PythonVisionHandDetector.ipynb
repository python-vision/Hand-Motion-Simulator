{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*CHAPTER I*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**HandDetector**\n",
        "\n",
        "github.com/python-vision/Hand-Moutio-Simulator"
      ],
      "metadata": {
        "id": "JlSr5_S6dvuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diCx7Bp2d1Uz",
        "outputId": "49e68012-7a49-4114-e8ad-9bc9b15668bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s80IDW6jegyt",
        "outputId": "dfdbfe86-2048-4868-d4d3-5210d818657e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.24)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.21 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bNG5oPqejxO",
        "outputId": "853a81f8-9ed1-46e2-87e1-4c8647eb4810"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GgFxcKPQhWdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mediapipe as md\n",
        "import cv2"
      ],
      "metadata": {
        "id": "-GzWQPPDenPU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ numpy: Used for numerical operations, especially handling arrays and image data efficiently.\n",
        "\n",
        "✅ mediapipe: A powerful framework for real-time hand tracking, face detection, pose estimation, and more.\n",
        "\n",
        "✅ cv2 (OpenCV): A popular library for image and video processing, used here for handling video input and visualization.\n",
        "\n",
        "These libraries are essential for computer vision tasks, enabling efficient image processing and machine learning-based detections. 🚀"
      ],
      "metadata": {
        "id": "FR1_N7enhIiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_hands = md.solutions.hands\n",
        "mp_draw = md.solutions.drawing_utils\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)"
      ],
      "metadata": {
        "id": "7aFvo0uoe03j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ mp_hands: Loads the MediaPipe Hands module for real-time hand tracking.\n",
        "\n",
        "✅ mp_draw: Imports drawing utilities to visualize detected hand landmarks.\n",
        "\n",
        "✅ hands: Initializes the hand tracking model with specific parameters:\n",
        "\n",
        "static_image_mode=False: Optimized for video streams (not static images).\n",
        "max_num_hands=1: Detects only one hand.\n",
        "min_detection_confidence=0.5: Minimum confidence (50%) required to detect a hand.\n",
        "This setup is essential for real-time hand tracking in videos or live streams. 🚀"
      ],
      "metadata": {
        "id": "Rbtm8SHHhSFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = 'capture.mp4'\n",
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "0cEAoqNNfB9Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ video_path: Stores the path of the video file (capture.mp4).\n",
        "\n",
        "✅ cap: Creates a VideoCapture object using OpenCV to read the video.\n",
        "\n",
        "This setup allows the program to load and process video frames for further analysis, such as hand tracking or object detection. 🚀"
      ],
      "metadata": {
        "id": "sf7uhb21hcxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "metadata": {
        "id": "s6pIPrpZgR15"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ fps: Retrieves the video's frames per second (FPS), which determines playback speed.\n",
        "\n",
        "✅ width: Gets the frame width (converted to an integer).\n",
        "\n",
        "✅ height: Gets the frame height (converted to an integer).\n",
        "\n",
        "These properties are useful for resizing, processing, or saving the video with the correct dimensions. 🚀\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Z6qsX3rhjgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []"
      ],
      "metadata": {
        "id": "RM4BkHWAggIw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    black_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(frame_rgb)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_draw.draw_landmarks(black_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "    frames.append(black_frame)\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "AubLz0xWgoYH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Reads and processes each video frame until the video ends.\n",
        "\n",
        "✅ Creates a black frame (black_frame) of the same size as the video for\n",
        "visualization.\n",
        "✅ Converts the frame to RGB (since MediaPipe requires RGB input).\n",
        "\n",
        "✅ Processes the frame to detect hand landmarks using MediaPipe.\n",
        "\n",
        "✅ If a hand is detected, landmarks are drawn on the black frame.\n",
        "\n",
        "✅ Stores the processed frame in the frames list for further use.\n",
        "\n",
        "✅ Releases the video capture after processing all frames.\n",
        "\n",
        "This loop effectively detects hands in a video and visualizes the landmarks on a black background, creating a clean representation of hand movements. 🚀"
      ],
      "metadata": {
        "id": "aoFMVxSEhwYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if frames:\n",
        "    out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "    print(\"output.mp4: Successfully Done\")\n",
        "else:\n",
        "    print(\"output.mp4: Failed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvQd4RWSgu06",
        "outputId": "053d8076-5b3a-4bc5-d063-46c090ab0934"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output.mp4: Successfully Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Checks if frames list is not empty before saving the video.\n",
        "\n",
        "✅ Creates a video writer (out) to save the processed frames as output.mp4:\n",
        "\n",
        "'mp4v': Specifies the video codec (MP4 format).\n",
        "fps: Sets the frame rate to match the original video.\n",
        "(width, height): Ensures the output has the same resolution.\n",
        "\n",
        "✅ Writes each frame from frames to the output video.\n",
        "\n",
        "✅ Releases the video writer after saving all frames.\n",
        "\n",
        "✅ Prints success or failure messages based on whether frames were processed.\n",
        "This code saves the processed hand-tracking frames into a new video file (output.mp4). 🚀"
      ],
      "metadata": {
        "id": "Dj-8Wa8fh6Me"
      }
    }
  ]
}